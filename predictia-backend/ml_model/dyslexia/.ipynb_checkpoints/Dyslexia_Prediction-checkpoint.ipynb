{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bf0cb868",
   "metadata": {},
   "source": [
    "# Final Working"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3696eb82",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "weight_decay is not a valid argument, kwargs should be empty  for `optimizer_experimental.Optimizer`.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[2], line 3\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# Load Trained Model from dyslexia_model\u001b[39;00m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m keras\n\u001b[1;32m----> 3\u001b[0m model \u001b[38;5;241m=\u001b[39m \u001b[43mkeras\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodels\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload_model\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mdyslexia_model\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\miniconda3\\envs\\tf\\lib\\site-packages\\keras\\utils\\traceback_utils.py:70\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     67\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[0;32m     68\u001b[0m     \u001b[38;5;66;03m# To get the full stack trace, call:\u001b[39;00m\n\u001b[0;32m     69\u001b[0m     \u001b[38;5;66;03m# `tf.debugging.disable_traceback_filtering()`\u001b[39;00m\n\u001b[1;32m---> 70\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28mNone\u001b[39m\n\u001b[0;32m     71\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m     72\u001b[0m     \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[1;32m~\\miniconda3\\envs\\tf\\lib\\site-packages\\keras\\optimizers\\optimizer_experimental\\optimizer.py:115\u001b[0m, in \u001b[0;36m_BaseOptimizer._process_kwargs\u001b[1;34m(self, kwargs)\u001b[0m\n\u001b[0;32m    109\u001b[0m     logging\u001b[38;5;241m.\u001b[39mwarning(\n\u001b[0;32m    110\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m is deprecated in `optimizer_experimental.Optimizer`\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    111\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m, please check the docstring for valid arguments.\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    112\u001b[0m         k,\n\u001b[0;32m    113\u001b[0m     )\n\u001b[0;32m    114\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 115\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\n\u001b[0;32m    116\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mk\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m is not a valid argument, kwargs should be empty \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    117\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m for `optimizer_experimental.Optimizer`.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    118\u001b[0m     )\n",
      "\u001b[1;31mTypeError\u001b[0m: weight_decay is not a valid argument, kwargs should be empty  for `optimizer_experimental.Optimizer`."
     ]
    }
   ],
   "source": [
    "# Load Trained Model from dyslexia_model\n",
    "from tensorflow import keras\n",
    "model = keras.models.load_model('dyslexia_model', compile=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "bb752922",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 1s 859ms/step\n",
      "Prediction ::  [[0. 1.]]\n"
     ]
    }
   ],
   "source": [
    "# Basic Testing based on image [ available in dataset ]\n",
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "# Read Actual Image\n",
    "char = cv2.imread('Gambo/Train/Reversal/1_31975.png')\n",
    "# Convert it to 28x28\n",
    "char28x28 = cv2.resize(char, (28, 28))\n",
    "\n",
    "# Pass converted image to model [ RGB Format ]\n",
    "print(\"Prediction :: \",model.predict(np.array([char28x28])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "4e7b12c6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - 0s 12ms/step\n",
      "Actual Prediction ::  [0.36363637 0.6363636 ]\n",
      "Dected, accuracy: 63.64%\n"
     ]
    }
   ],
   "source": [
    "# Actual Testing based on captured image\n",
    "'''\n",
    "    1. Read Handwriting image\n",
    "    2. Convert it to grayscale\n",
    "    3. Obtained it's Threshold\n",
    "    4. Clean image [ morphological operations ]\n",
    "    5. Detect color changes on image [ findContours ]\n",
    "        5.1 : Iterate over each change\n",
    "        5.2 : get exact character co-ordinates [ boundingRect ]\n",
    "        5.3 : Crop character from actual image using co-ordinates\n",
    "        5.4 : Convert cropped image into RGB \n",
    "        5.5 : Resize it to 28x28\n",
    "        5.6 : store all characters in array [seperated_chars]\n",
    "    6. Pass seperated_chars array to model for prediction\n",
    "    7. Obtain mean of predicted array [ column ]\n",
    "    8. (prediction_mean_arr[0] > prediction_mean_arr[1]) ? Not Dected : Dected\n",
    "'''\n",
    "# Load the image\n",
    "img = cv2.imread('input/hw_05.jpg')\n",
    "\n",
    "# Convert the image to grayscale\n",
    "gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "# Threshold the image to segment the characters\n",
    "_, thresholded = cv2.threshold(gray, 128, 255, cv2.THRESH_BINARY_INV)\n",
    "\n",
    "# Perform morphological operations to clean up the image\n",
    "kernel = cv2.getStructuringElement(cv2.MORPH_ELLIPSE, (3,3))\n",
    "thresholded = cv2.morphologyEx(thresholded, cv2.MORPH_CLOSE, kernel)\n",
    "\n",
    "# Find the contours of the characters \n",
    "contours, _ = cv2.findContours(thresholded, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "\n",
    "# Iterate through the contours\n",
    "seperated_chars = []\n",
    "for i, contour in enumerate(contours):\n",
    "    # Get the bounding rectangle of the contour\n",
    "    x, y, w, h = cv2.boundingRect(contour)\n",
    "    # Crop the character using array slicing\n",
    "    character = thresholded[y:y+h, x:x+w]\n",
    "    \n",
    "    #convert each image into RGB format and pass it to model\n",
    "    rgb = cv2.cvtColor(character, cv2.COLOR_GRAY2RGB)\n",
    "    seperated_chars.append(cv2.resize(rgb, (28, 28)))\n",
    "    \n",
    "prediction_arr = model.predict(np.array(seperated_chars))\n",
    "prediction_mean_arr = np.mean(prediction_arr, axis = 0)\n",
    "print(\"Actual Prediction :: \",prediction_mean_arr)\n",
    "\n",
    "if (prediction_mean_arr[0] > prediction_mean_arr[1]):\n",
    "    print(\"Not Dected, accuracy: {:5.2f}%\".format(100 * prediction_mean_arr[0]))\n",
    "else:\n",
    "    print(\"Dected, accuracy: {:5.2f}%\".format(100 * prediction_mean_arr[1]))\n",
    "    \n",
    "cv2.imshow('Input Image', thresholded)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a85c6847",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df31fa71",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
