{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bf0cb868",
   "metadata": {},
   "source": [
    "# Final Working"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3696eb82",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load Trained Model from dyslexia_model\n",
    "from tensorflow import keras\n",
    "model = keras.models.load_model('dyslexia_model', compile=False)\n",
    "model.compile(optimizer='adam', loss='mean_squared_error',metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "bb752922",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 1s 859ms/step\n",
      "Prediction ::  [[0. 1.]]\n"
     ]
    }
   ],
   "source": [
    "# Basic Testing based on image [ available in dataset ]\n",
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "# Read Actual Image\n",
    "char = cv2.imread('Gambo/Train/Reversal/1_31975.png')\n",
    "# Convert it to 28x28\n",
    "char28x28 = cv2.resize(char, (28, 28))\n",
    "\n",
    "# Pass converted image to model [ RGB Format ]\n",
    "print(\"Prediction :: \",model.predict(np.array([char28x28])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "4e7b12c6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - 0s 12ms/step\n",
      "Actual Prediction ::  [0.36363637 0.6363636 ]\n",
      "Dected, accuracy: 63.64%\n"
     ]
    }
   ],
   "source": [
    "# Actual Testing based on captured image\n",
    "'''\n",
    "    1. Read Handwriting image\n",
    "    2. Convert it to grayscale\n",
    "    3. Obtained it's Threshold\n",
    "    4. Clean image [ morphological operations ]\n",
    "    5. Detect color changes on image [ findContours ]\n",
    "        5.1 : Iterate over each change\n",
    "        5.2 : get exact character co-ordinates [ boundingRect ]\n",
    "        5.3 : Crop character from actual image using co-ordinates\n",
    "        5.4 : Convert cropped image into RGB \n",
    "        5.5 : Resize it to 28x28\n",
    "        5.6 : store all characters in array [seperated_chars]\n",
    "    6. Pass seperated_chars array to model for prediction\n",
    "    7. Obtain mean of predicted array [ column ]\n",
    "    8. (prediction_mean_arr[0] > prediction_mean_arr[1]) ? Not Dected : Dected\n",
    "'''\n",
    "# Load the image\n",
    "img = cv2.imread('input/hw_05.jpg')\n",
    "\n",
    "# Convert the image to grayscale\n",
    "gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "# Threshold the image to segment the characters\n",
    "_, thresholded = cv2.threshold(gray, 128, 255, cv2.THRESH_BINARY_INV)\n",
    "\n",
    "# Perform morphological operations to clean up the image\n",
    "kernel = cv2.getStructuringElement(cv2.MORPH_ELLIPSE, (3,3))\n",
    "thresholded = cv2.morphologyEx(thresholded, cv2.MORPH_CLOSE, kernel)\n",
    "\n",
    "# Find the contours of the characters \n",
    "contours, _ = cv2.findContours(thresholded, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "\n",
    "# Iterate through the contours\n",
    "seperated_chars = []\n",
    "for i, contour in enumerate(contours):\n",
    "    # Get the bounding rectangle of the contour\n",
    "    x, y, w, h = cv2.boundingRect(contour)\n",
    "    # Crop the character using array slicing\n",
    "    character = thresholded[y:y+h, x:x+w]\n",
    "    \n",
    "    #convert each image into RGB format and pass it to model\n",
    "    rgb = cv2.cvtColor(character, cv2.COLOR_GRAY2RGB)\n",
    "    seperated_chars.append(cv2.resize(rgb, (28, 28)))\n",
    "    \n",
    "prediction_arr = model.predict(np.array(seperated_chars))\n",
    "prediction_mean_arr = np.mean(prediction_arr, axis = 0)\n",
    "print(\"Actual Prediction :: \",prediction_mean_arr)\n",
    "\n",
    "if (prediction_mean_arr[0] > prediction_mean_arr[1]):\n",
    "    print(\"Not Dected, accuracy: {:5.2f}%\".format(100 * prediction_mean_arr[0]))\n",
    "else:\n",
    "    print(\"Dected, accuracy: {:5.2f}%\".format(100 * prediction_mean_arr[1]))\n",
    "    \n",
    "cv2.imshow('Input Image', thresholded)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a85c6847",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df31fa71",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
